services:
  llama-flask-api:
    build: .
    depends_on:
      ollama:
        condition: service_started
    ports:
      - "5000:5000"
  ollama:
    image: "ollama/ollama"
    ports:
      - "11434:11434"
